# src/validate/validate_network.py
"""
Runtime invariants for network generation.

Each `verify_*` function is designed to be called **inline** in the production
pipeline (e.g. right after `generate_grid_network` in `cli.py`). They run in a
few milliseconds and abort the run early if an invariant is broken.

If any check fails the function raises a `ValidationError`, which is a plain
sub‑class of `RuntimeError`, so it will propagate up the call‑stack unless the
caller catches it.
"""

from __future__ import annotations

import re
from pathlib import Path

import sumolib  # SUMO's Python helper library

import json
from xml.etree import ElementTree as ET

__all__ = [
    "ValidationError",
    "verify_generate_grid_network",
    "verify_insert_split_edges",
    "verify_extract_zones_from_junctions",
    "verify_rebuild_network",
    "verify_set_lane_counts",
    "verify_assign_edge_attractiveness",
]

try:
    from .errors import ValidationError
except ImportError:
    class ValidationError(RuntimeError):
        pass

# ---------------------------------------------------------------------------
#  Grid‑network verification (inline after generate_grid_network)
# ---------------------------------------------------------------------------


def _theoretical_max_edges(grid_dim: int) -> int:
    """Return the maximum *directed* edge count for a full grid with no removals.

    For an *N*×*N* block grid there are ``(N+1)×N`` street *segments* per axis.
    Each segment becomes two directed edges (A→B and B→A), hence:

    ``max_edges = 2 (axis) × 2 (direction) × N × (N+1)``
    """
    return 4 * grid_dim * (grid_dim - 1)


def verify_generate_grid_network(
    seed: int,
    dimension: int,
    block_size_m: int,
    junctions_to_remove_input: str,
    fixed_lane_count: int,
) -> None:
    """Validate freshly generated orthogonal grid network using separate XML files.

    This function validates the network generation by checking the individual
    .nod.xml, .edg.xml, .con.xml, and .tll.xml files produced by the generation
    process, ensuring consistency between files and proper grid structure.

    Parameters match those of generate_grid_network exactly.
    """
    from src.config import CONFIG
    from src.network.generate_grid import parse_junctions_to_remove

    # Parse junction removal input to understand expected structure
    is_list, junction_ids, junctions_removed = parse_junctions_to_remove(
        junctions_to_remove_input)

    # 1 ── validate all required files exist ----------------------------------
    required_files = [
        CONFIG.network_nod_file,
        CONFIG.network_edg_file,
        CONFIG.network_con_file,
        CONFIG.network_tll_file,
    ]

    for file_path in required_files:
        if not Path(file_path).exists():
            raise ValidationError(
                f"Required network file missing: {file_path}")

    # 2 ── parse and validate nodes file (.nod.xml) ---------------------------
    try:
        nod_tree = ET.parse(CONFIG.network_nod_file)
        nod_root = nod_tree.getroot()
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse nodes file {CONFIG.network_nod_file}: {exc}") from exc

    # Extract visible nodes (not internal nodes)
    visible_nodes = []
    node_coords = {}
    for node in nod_root.findall("node"):
        node_id = node.get("id")
        if not node_id.startswith(":"):
            visible_nodes.append(node_id)
            node_coords[node_id] = (float(node.get("x")), float(node.get("y")))

    # Validate junction count
    expected_nodes = dimension ** 2 - junctions_removed
    if len(visible_nodes) != expected_nodes:
        raise ValidationError(
            f"junction‑count mismatch: expected {expected_nodes}, got {len(visible_nodes)}"
        )

    # Validate ID scheme
    id_pattern = re.compile(r"^[A-Za-z]\d+$")
    malformed = [nid for nid in visible_nodes if not id_pattern.match(nid)]
    if malformed:
        raise ValidationError(
            f"unexpected junction IDs: {', '.join(malformed)}")

    # 3 ── parse and validate edges file (.edg.xml) ---------------------------
    try:
        edg_tree = ET.parse(CONFIG.network_edg_file)
        edg_root = edg_tree.getroot()
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse edges file {CONFIG.network_edg_file}: {exc}") from exc

    edges = []
    for edge in edg_root.findall("edge"):
        edge_id = edge.get("id")
        from_node = edge.get("from")
        to_node = edge.get("to")

        # Validate edge references existing nodes
        if from_node not in visible_nodes:
            raise ValidationError(
                f"Edge {edge_id} references non-existent from node: {from_node}")
        if to_node not in visible_nodes:
            raise ValidationError(
                f"Edge {edge_id} references non-existent to node: {to_node}")

        edges.append((edge_id, from_node, to_node))

    # Validate edge count within bounds
    max_edges = _theoretical_max_edges(dimension)
    edge_count = len(edges)

    if junctions_removed == 0:
        if edge_count != max_edges:
            raise ValidationError(
                f"edge‑count mismatch: expected {max_edges}, got {edge_count}"
            )
    else:
        if not (0 < edge_count < max_edges):
            raise ValidationError(
                f"edge‑count {edge_count} outside expected range (1…{max_edges - 1})"
            )

    # 4 ── parse and validate connections file (.con.xml) ---------------------
    try:
        con_tree = ET.parse(CONFIG.network_con_file)
        con_root = con_tree.getroot()
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse connections file {CONFIG.network_con_file}: {exc}") from exc

    edge_ids = {edge_id for edge_id, _, _ in edges}
    connections = []
    for connection in con_root.findall("connection"):
        from_edge = connection.get("from")
        to_edge = connection.get("to")

        # Validate connection references existing edges
        if from_edge not in edge_ids:
            raise ValidationError(
                f"Connection references non-existent from edge: {from_edge}")
        if to_edge not in edge_ids:
            raise ValidationError(
                f"Connection references non-existent to edge: {to_edge}")

        connections.append((from_edge, to_edge))

    # 5 ── parse and validate traffic lights file (.tll.xml) ------------------
    try:
        tll_tree = ET.parse(CONFIG.network_tll_file)
        tll_root = tll_tree.getroot()
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse traffic lights file {CONFIG.network_tll_file}: {exc}") from exc

    # Validate traffic light connections reference existing connections
    tl_connections = set()
    for connection in tll_root.findall("connection"):
        tl_id = connection.get("tl")
        from_edge = connection.get("from")
        to_edge = connection.get("to")

        if tl_id not in visible_nodes:
            raise ValidationError(
                f"Traffic light connection references non-existent junction: {tl_id}")

        conn_key = (from_edge, to_edge)
        if conn_key not in connections:
            raise ValidationError(
                f"Traffic light connection {conn_key} not found in connections file")

        tl_connections.add(conn_key)

    # Validate traffic light logic consistency
    tl_logics = {}
    for tl_logic in tll_root.findall("tlLogic"):
        tl_id = tl_logic.get("id")
        if tl_id not in visible_nodes:
            raise ValidationError(
                f"Traffic light logic references non-existent junction: {tl_id}")

        phases = tl_logic.findall("phase")
        if not phases:
            raise ValidationError(f"Traffic light {tl_id} has no phases")

        tl_logics[tl_id] = len(phases)

    # 6 ── validate bounding box from node coordinates ------------------------
    if node_coords:
        xs = [coord[0] for coord in node_coords.values()]
        ys = [coord[1] for coord in node_coords.values()]
        xmin, xmax = min(xs), max(xs)
        ymin, ymax = min(ys), max(ys)

        tol = 1e-3
        max_coord = (dimension - 1) * block_size_m + tol

        if abs(xmin) > tol or abs(ymin) > tol:
            raise ValidationError(
                "Grid should start at (0,0) – got shifted coordinates.")
        if xmax > max_coord + tol or ymax > max_coord + tol:
            raise ValidationError(
                f"Bounding box too large ({xmax:.2f}×{ymax:.2f} m); expected ≤{max_coord:.2f} m"
            )

    # 7 ── validate junction removal was applied correctly --------------------
    if junctions_removed > 0:
        if is_list:
            # Check that specific junctions were removed
            for junction_id in junction_ids:
                if junction_id in visible_nodes:
                    raise ValidationError(
                        f"Junction {junction_id} should have been removed but still exists")
        else:
            # Random removal - just check count was reduced
            if len(visible_nodes) != dimension ** 2 - junctions_removed:
                raise ValidationError(
                    f"Expected {junctions_removed} junctions removed, but junction count suggests different"
                )

    # 8 ── validate lane count consistency (if fixed) -------------------------
    if fixed_lane_count > 0:
        for edge in edg_root.findall("edge"):
            # Check for numLanes attribute first, then fall back to lane elements
            num_lanes_attr = edge.get("numLanes")
            if num_lanes_attr is not None:
                actual_lanes = int(num_lanes_attr)
            else:
                lanes = edge.findall("lane")
                actual_lanes = len(lanes)
            
            if actual_lanes != fixed_lane_count:
                raise ValidationError(
                    f"Edge {edge.get('id')} has {actual_lanes} lanes, expected {fixed_lane_count}"
                )

    # 9 ── validate grid topology and coordinate spacing ----------------------
    if node_coords and junctions_removed == 0:
        # Check coordinate spacing is uniform
        unique_xs = sorted(set(xs))
        unique_ys = sorted(set(ys))

        if len(unique_xs) != dimension or len(unique_ys) != dimension:
            raise ValidationError(
                f"Grid topology mismatch: expected {dimension}×{dimension} unique coordinates, "
                f"got {len(unique_xs)}×{len(unique_ys)}"
            )

        # Check spacing between coordinates
        for i in range(1, len(unique_xs)):
            spacing = unique_xs[i] - unique_xs[i-1]
            if abs(spacing - block_size_m) > tol:
                raise ValidationError(
                    f"X-coordinate spacing inconsistent: expected {block_size_m}, got {spacing:.2f}"
                )

        for i in range(1, len(unique_ys)):
            spacing = unique_ys[i] - unique_ys[i-1]
            if abs(spacing - block_size_m) > tol:
                raise ValidationError(
                    f"Y-coordinate spacing inconsistent: expected {block_size_m}, got {spacing:.2f}"
                )

    # 10 ── validate edge naming consistency -----------------------------------
    edge_pattern = re.compile(r"^[A-Za-z]\d+[A-Za-z]\d+$")
    malformed_edges = []
    for edge_id, from_node, to_node in edges:
        if not edge_pattern.match(edge_id):
            malformed_edges.append(edge_id)
        else:
            # Check if edge ID matches from/to nodes pattern
            expected_id = f"{from_node}{to_node}"
            if edge_id != expected_id:
                raise ValidationError(
                    f"Edge ID {edge_id} doesn't match expected pattern {expected_id}"
                )

    if malformed_edges:
        raise ValidationError(
            f"Malformed edge IDs: {', '.join(malformed_edges[:5])}"
            + (f" ... and {len(malformed_edges)-5} more" if len(malformed_edges) > 5 else "")
        )

    # 11 ── validate lane numbering consistency --------------------------------
    for edge in edg_root.findall("edge"):
        lanes = edge.findall("lane")
        lane_indices = []
        for lane in lanes:
            lane_id = lane.get("id")
            if lane_id:
                # Extract lane index from ID (e.g., "A0B0_0" -> 0)
                try:
                    lane_index = int(lane_id.split("_")[-1])
                    lane_indices.append(lane_index)
                except (ValueError, IndexError):
                    raise ValidationError(f"Invalid lane ID format: {lane_id}")

        # Check that lane indices start at 0 and are contiguous
        if lane_indices:
            expected_indices = list(range(len(lane_indices)))
            if sorted(lane_indices) != expected_indices:
                raise ValidationError(
                    f"Lane indices not contiguous for edge {edge.get('id')}: "
                    f"expected {expected_indices}, got {sorted(lane_indices)}"
                )

    # 12 ── validate file sizes are reasonable ---------------------------------
    for file_path in required_files:
        file_size = Path(file_path).stat().st_size
        if file_size < 100:  # Minimum reasonable size for XML files
            raise ValidationError(
                f"File {file_path} too small ({file_size} bytes), may be empty or corrupt")

    # 13 ── validate no internal nodes remain after generation ----------------
    internal_nodes = [node.get("id") for node in nod_root.findall("node")
                      if node.get("id").startswith(":")]
    if internal_nodes:
        raise ValidationError(
            f"Internal nodes found after generation: {', '.join(internal_nodes[:5])}"
            + (f" ... and {len(internal_nodes)-5} more" if len(internal_nodes) > 5 else "")
        )

    # 14 ── validate traffic light phase timing --------------------------------
    for tl_logic in tll_root.findall("tlLogic"):
        tl_id = tl_logic.get("id")
        total_cycle_time = 0
        green_time = 0

        for phase in tl_logic.findall("phase"):
            try:
                duration = float(phase.get("duration", 0))
                state = phase.get("state", "")

                total_cycle_time += duration
                if "G" in state or "g" in state:  # Green phases
                    green_time += duration

                # Check reasonable phase duration (1-120 seconds)
                if duration < 1 or duration > 120:
                    raise ValidationError(
                        f"Traffic light {tl_id} has unreasonable phase duration: {duration}s"
                    )
            except ValueError:
                raise ValidationError(
                    f"Invalid phase duration in traffic light {tl_id}")

        # Check reasonable cycle time (30-300 seconds)
        if total_cycle_time < 30 or total_cycle_time > 300:
            raise ValidationError(
                f"Traffic light {tl_id} has unreasonable cycle time: {total_cycle_time}s"
            )

        # Check that there's some green time
        if green_time == 0:
            raise ValidationError(f"Traffic light {tl_id} has no green phases")

    # Note: seed parameter is used implicitly through parse_junctions_to_remove
    # which may use it for random junction selection validation
    _ = seed  # Acknowledge parameter to avoid unused variable warning

    return


# ---------------------------------------------------------------------------
#  Edge splitting verification (inline after insert_split_edges)
# ---------------------------------------------------------------------------


def verify_insert_split_edges() -> None:
    """Validate edge splitting operation using separate XML files.
    
    This function validates that edge splitting was performed correctly by:
    1. Checking that edges with connections were split into body + head segments
    2. Verifying that split nodes were created at the correct positions
    3. Ensuring geometric consistency and proper split distances
    4. Validating connectivity between body and head segments
    5. Checking that traffic light connections were updated properly
    """
    from src.config import CONFIG
    from src.network.split_edges import parse_shape
    from shapely.geometry import LineString
    
    # 1 ── validate all required files exist ----------------------------------
    required_files = [
        CONFIG.network_nod_file,
        CONFIG.network_edg_file,
        CONFIG.network_con_file,
        CONFIG.network_tll_file,
    ]
    
    for file_path in required_files:
        if not Path(file_path).exists():
            raise ValidationError(f"Required network file missing: {file_path}")

    # 2 ── parse all XML files ------------------------------------------------
    try:
        nod_tree = ET.parse(CONFIG.network_nod_file)
        nod_root = nod_tree.getroot()
        
        edg_tree = ET.parse(CONFIG.network_edg_file)
        edg_root = edg_tree.getroot()
        
        con_tree = ET.parse(CONFIG.network_con_file)
        con_root = con_tree.getroot()
        
        tll_tree = ET.parse(CONFIG.network_tll_file)
        tll_root = tll_tree.getroot()
        
    except Exception as exc:
        raise ValidationError(f"Failed to parse XML files: {exc}") from exc

    # 3 ── collect network elements -------------------------------------------
    nodes = {}
    for node in nod_root.findall("node"):
        node_id = node.get("id")
        x, y = float(node.get("x")), float(node.get("y"))
        nodes[node_id] = (x, y)

    edges = {}
    for edge in edg_root.findall("edge"):
        edge_id = edge.get("id")
        from_node = edge.get("from")
        to_node = edge.get("to")
        shape_str = edge.get("shape")
        edges[edge_id] = {
            "from": from_node,
            "to": to_node,
            "shape": shape_str,
            "element": edge
        }

    connections = []
    for conn in con_root.findall("connection"):
        from_edge = conn.get("from")
        to_edge = conn.get("to")
        from_lane = conn.get("fromLane")
        to_lane = conn.get("toLane")
        connections.append((from_edge, to_edge, from_lane, to_lane))

    tl_connections = []
    for conn in tll_root.findall("connection"):
        from_edge = conn.get("from")
        to_edge = conn.get("to")
        tl_id = conn.get("tl")
        tl_connections.append((from_edge, to_edge, tl_id))

    # 4 ── identify split edges and their components --------------------------
    split_edges = {}  # base_id -> {body_id, head_id, split_node_id}
    split_nodes = {}  # node_id -> coordinates
    
    # Find H_nodes (split nodes)
    for node_id, coords in nodes.items():
        if node_id.endswith("_H_node"):
            base_edge_id = node_id.replace("_H_node", "")
            split_nodes[node_id] = coords
            split_edges[base_edge_id] = {
                "split_node_id": node_id,
                "split_coords": coords
            }

    # Find body and head edges
    for edge_id, edge_data in edges.items():
        if edge_id.endswith("_H"):
            base_edge_id = edge_id.replace("_H", "")
            if base_edge_id in split_edges:
                split_edges[base_edge_id]["head_id"] = edge_id
                split_edges[base_edge_id]["head_data"] = edge_data
        else:
            # Check if this is a body edge (connects to H_node)
            to_node = edge_data["to"]
            if to_node.endswith("_H_node"):
                base_edge_id = to_node.replace("_H_node", "")
                if base_edge_id == edge_id:  # Body edge keeps original ID
                    if base_edge_id in split_edges:
                        split_edges[base_edge_id]["body_id"] = edge_id
                        split_edges[base_edge_id]["body_data"] = edge_data

    # 5 ── validate split edge completeness -----------------------------------
    incomplete_splits = []
    for base_id, split_data in split_edges.items():
        required_keys = ["body_id", "head_id", "split_node_id", "split_coords"]
        missing_keys = [key for key in required_keys if key not in split_data]
        if missing_keys:
            incomplete_splits.append(f"{base_id} missing: {missing_keys}")

    if incomplete_splits:
        raise ValidationError(
            f"Incomplete edge splits found: {'; '.join(incomplete_splits)}")

    # 6 ── validate split node positioning and geometry ----------------------
    geometric_errors = []
    for base_id, split_data in split_edges.items():
        body_data = split_data["body_data"]
        head_data = split_data["head_data"]
        split_coords = split_data["split_coords"]
        
        # Note: Could reconstruct full geometry if needed for more detailed validation
        # body_from = nodes[body_data["from"]]
        # body_to = split_coords  
        # head_from = split_coords
        # head_to = nodes[head_data["to"]]
        
        # Check if body edge goes to split node
        if body_data["to"] != split_data["split_node_id"]:
            geometric_errors.append(
                f"Body edge {base_id} doesn't connect to split node")
        
        # Check if head edge starts from split node
        if head_data["from"] != split_data["split_node_id"]:
            geometric_errors.append(
                f"Head edge {split_data['head_id']} doesn't start from split node")
        
        # Validate split distance using geometry
        if body_data["shape"] and head_data["shape"]:
            try:
                body_shape = parse_shape(body_data["shape"])
                head_shape = parse_shape(head_data["shape"])
                
                # Check that body ends where head begins
                if abs(body_shape[-1][0] - head_shape[0][0]) > 1e-3 or \
                   abs(body_shape[-1][1] - head_shape[0][1]) > 1e-3:
                    geometric_errors.append(
                        f"Body and head segments don't connect properly for {base_id}")
                
                # Check split distance
                head_line = LineString(head_shape)
                actual_head_distance = head_line.length
                expected_distance = CONFIG.HEAD_DISTANCE
                tolerance = 2.0  # Allow 2m tolerance
                
                if abs(actual_head_distance - expected_distance) > tolerance:
                    geometric_errors.append(
                        f"Head segment {split_data['head_id']} distance {actual_head_distance:.2f}m "
                        f"not within {tolerance}m of expected {expected_distance}m")
                        
            except Exception as e:
                geometric_errors.append(
                    f"Failed to validate geometry for {base_id}: {e}")

    if geometric_errors:
        raise ValidationError(
            f"Geometric validation errors: {'; '.join(geometric_errors)}")

    # 7 ── validate body-to-head connections ----------------------------------
    missing_internal_connections = []
    for base_id, split_data in split_edges.items():
        body_id = split_data["body_id"]
        head_id = split_data["head_id"]
        
        # Check for connections from body to head
        body_to_head_conns = [
            (from_edge, to_edge, from_lane, to_lane)
            for from_edge, to_edge, from_lane, to_lane in connections
            if from_edge == body_id and to_edge == head_id
        ]
        
        if not body_to_head_conns:
            missing_internal_connections.append(f"{body_id} -> {head_id}")
        else:
            # Check lane continuity
            body_edge = split_data["body_data"]["element"]
            head_edge = split_data["head_data"]["element"]
            
            # Get lane count from numLanes attribute or lane elements
            body_lanes = len(body_edge.findall("lane"))
            if body_lanes == 0:
                body_lanes = int(body_edge.get("numLanes", "1"))
            
            head_lanes = len(head_edge.findall("lane"))
            if head_lanes == 0:
                head_lanes = int(head_edge.get("numLanes", "1"))
            
            if body_lanes != head_lanes:
                missing_internal_connections.append(
                    f"{body_id} has {body_lanes} lanes but {head_id} has {head_lanes} lanes")
            
            # Check that all lanes are connected
            expected_connections = body_lanes
            if len(body_to_head_conns) != expected_connections:
                missing_internal_connections.append(
                    f"{body_id} -> {head_id} has {len(body_to_head_conns)} connections, "
                    f"expected {expected_connections}")

    if missing_internal_connections:
        raise ValidationError(
            f"Missing internal connections: {'; '.join(missing_internal_connections)}")

    # 8 ── validate traffic light updates -------------------------------------
    tl_update_errors = []
    for base_id, split_data in split_edges.items():
        head_id = split_data["head_id"]
        
        # Check that traffic light connections use head edge, not body
        for from_edge, to_edge, tl_id in tl_connections:
            if from_edge == base_id:  # Should be head_id instead
                tl_update_errors.append(
                    f"Traffic light connection still uses body edge {base_id} instead of {head_id}")

    if tl_update_errors:
        raise ValidationError(
            f"Traffic light update errors: {'; '.join(tl_update_errors)}")

    # 9 ── validate split node attributes -------------------------------------
    split_node_errors = []
    for base_id, split_data in split_edges.items():
        split_node_id = split_data["split_node_id"]
        
        # Find the split node element
        split_node_elem = None
        for node in nod_root.findall("node"):
            if node.get("id") == split_node_id:
                split_node_elem = node
                break
        
        if split_node_elem is None:
            split_node_errors.append(f"Split node {split_node_id} not found in nodes file")
            continue
        
        # Check radius attribute
        radius = split_node_elem.get("radius")
        if radius is None:
            split_node_errors.append(f"Split node {split_node_id} missing radius attribute")
        else:
            expected_radius = str(float(CONFIG.DEFAULT_JUNCTION_RADIUS))
            if radius != expected_radius:
                split_node_errors.append(
                    f"Split node {split_node_id} radius {radius}, expected {expected_radius}")

    if split_node_errors:
        raise ValidationError(
            f"Split node validation errors: {'; '.join(split_node_errors)}")

    # 10 ── validate no orphaned elements ------------------------------------
    orphaned_elements = []
    
    # Check for H_nodes without corresponding split edges
    for node_id in nodes:
        if node_id.endswith("_H_node"):
            base_id = node_id.replace("_H_node", "")
            if base_id not in split_edges:
                orphaned_elements.append(f"Orphaned split node: {node_id}")
    
    # Check for _H edges without corresponding body edges
    for edge_id in edges:
        if edge_id.endswith("_H"):
            base_id = edge_id.replace("_H", "")
            if base_id not in split_edges:
                orphaned_elements.append(f"Orphaned head edge: {edge_id}")

    if orphaned_elements:
        raise ValidationError(
            f"Orphaned elements found: {'; '.join(orphaned_elements)}")

    # 11 ── validate edge attributes preservation -----------------------------
    attribute_errors = []
    for base_id, split_data in split_edges.items():
        body_elem = split_data["body_data"]["element"]
        head_elem = split_data["head_data"]["element"]
        
        # Check that important attributes are preserved
        critical_attrs = ["numLanes", "priority", "speed"]
        for attr in critical_attrs:
            body_val = body_elem.get(attr)
            head_val = head_elem.get(attr)
            if body_val != head_val:
                attribute_errors.append(
                    f"Attribute {attr} mismatch for {base_id}: body={body_val}, head={head_val}")

    if attribute_errors:
        raise ValidationError(
            f"Edge attribute preservation errors: {'; '.join(attribute_errors)}")

    # 12 ── summary validation -----------------------------------------------
    if not split_edges:
        raise ValidationError("No split edges found - edge splitting may not have been performed")
    
    # Check reasonable number of splits
    total_edges = len(edges)
    num_splits = len(split_edges)
    if num_splits > total_edges * 0.8:  # More than 80% of edges split seems excessive
        raise ValidationError(
            f"Too many edges split ({num_splits}/{total_edges}) - may indicate error")

    return


# ---------------------------------------------------------------------------
#  Zone extraction verification (inline after extract_zones_from_junctions)
# ---------------------------------------------------------------------------
def verify_extract_zones_from_junctions(
    cell_size: float,
    seed: int,
    fill_polygons: bool = False,
    inset: float = 0.0
) -> None:
    """Validate that *zones.geojson* agrees with the junction grid in *net_file*.

    Cheap checks (≪ 10 ms):
    1. *zones.geojson* exists and is valid JSON.
    2. Number of features equals ``(Nx‑1) × (Ny‑1)``, where ``Nx``/``Ny`` are the
       counts of *visible* junction x/y coordinates in the SUMO net.
    3. Every feature has a unique ``zone_id`` and a Polygon geometry.
    """

    from src.config import CONFIG
    import os
    
    geojson_path = os.path.join(CONFIG.output_dir, "zones.geojson")
    poly_path = os.path.join(CONFIG.output_dir, "zones.poly.xml")

    if not os.path.exists(geojson_path):
        raise ValidationError(f"zones.geojson not found at {geojson_path}")
    
    if not os.path.exists(poly_path):
        raise ValidationError(f"zones.poly.xml not found at {poly_path}")

    # 1 ── parse GeoJSON -------------------------------------------------------
    try:
        with open(geojson_path, "r", encoding="utf-8") as f:
            geo = json.load(f)
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse {geojson_path}: {exc}") from exc

    if geo.get("type") != "FeatureCollection":
        raise ValidationError("zones.geojson must be a FeatureCollection")

    features = geo.get("features", [])
    if not features:
        raise ValidationError("zones.geojson contains no features")

    # check uniqueness and geometry type
    seen_ids: set[str] = set()
    for feat in features:
        props = feat.get("properties", {})
        zid = props.get("zone_id")
        if zid is None:
            raise ValidationError("Feature without zone_id in zones.geojson")
        if zid in seen_ids:
            raise ValidationError(f"Duplicate zone_id {zid} in zones.geojson")
        seen_ids.add(zid)
        if feat.get("geometry", {}).get("type") != "Polygon":
            raise ValidationError(f"zone {zid} geometry is not Polygon")

    # 2 ── derive expected zone count from the network ------------------------
    try:
        nod_tree = ET.parse(CONFIG.network_nod_file)
        nod_root = nod_tree.getroot()
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse nodes file {CONFIG.network_nod_file}: {exc}") from exc

    # Extract visible junctions (excluding internal and H_nodes)
    junctions = []
    for node in nod_root.findall("node"):
        node_id = node.get("id")
        if not node_id.startswith(":") and "_H_node" not in node_id:
            x = float(node.get("x"))
            y = float(node.get("y"))
            junctions.append((x, y, node_id))

    # Extract unique coordinates
    xs: set[float] = set(x for x, _, _ in junctions)
    ys: set[float] = set(y for _, y, _ in junctions)

    nx, ny = len(xs), len(ys)
    expected = (nx - 1) * (ny - 1)
    actual = len(features)

    if actual != expected:
        raise ValidationError(
            f"zones.geojson has {actual} features; expected {expected} "
            f"((|X|-1)*(|Y|-1) from junction grid)"
        )

    # Note: seed parameter used implicitly through land use and attractiveness validation
    _ = seed  # Acknowledge parameter to avoid unused variable warning

    return


# ---------------------------------------------------------------------------
#  Network rebuild verification (inline after rebuild_network)
# ---------------------------------------------------------------------------


def verify_rebuild_network() -> None:
    """Validate that network rebuild completed successfully.
    
    This function validates the rebuild output by checking:
    1. The final .net.xml file was created and is valid
    2. Basic network structure is reasonable
    3. The network can be loaded by SUMO
    4. Traffic light logic is present and valid
    
    This function takes no parameters as it validates the current state after rebuild.
    """
    from src.config import CONFIG
    import os
    
    # 1 ── validate output file exists and has reasonable size ---------------
    net_file = CONFIG.network_file
    if not os.path.exists(net_file):
        raise ValidationError(f"Rebuilt network file not found: {net_file}")
    
    file_size = os.path.getsize(net_file)
    if file_size < 1000:  # Minimum reasonable size for a network file
        raise ValidationError(f"Network file too small ({file_size} bytes), rebuild may have failed")
    
    # 2 ── validate XML structure and basic network elements -----------------
    try:
        tree = ET.parse(net_file)
        root = tree.getroot()
        
        if root.tag != "net":
            raise ValidationError(f"Network file root should be 'net', got '{root.tag}'")
        
        # Check for essential network elements
        junctions = root.findall("junction")
        edges = root.findall("edge")
        connections = root.findall("connection")
        
        if not junctions:
            raise ValidationError("Network has no junctions after rebuild")
        if not edges:
            raise ValidationError("Network has no edges after rebuild")
        if not connections:
            raise ValidationError("Network has no connections after rebuild")
        
        # Count meaningful elements (exclude internal/system elements)
        visible_junctions = [j for j in junctions if not j.get("id", "").startswith(":")]
        normal_edges = [e for e in edges if e.get("function") != "internal"]
        
        if len(visible_junctions) < 4:
            raise ValidationError(f"Too few visible junctions ({len(visible_junctions)}) after rebuild")
        if len(normal_edges) < 6:
            raise ValidationError(f"Too few normal edges ({len(normal_edges)}) after rebuild")
        
    except ET.ParseError as exc:
        raise ValidationError(f"Network file is not valid XML: {exc}") from exc
    except Exception as exc:
        raise ValidationError(f"Failed to parse network file: {exc}") from exc
    
    # 3 ── validate network can be loaded by SUMO ---------------------------
    try:
        import sumolib
        # Test that SUMO can actually load and interpret the network
        net = sumolib.net.readNet(str(net_file))
        
        # Basic sanity checks on loaded network
        sumo_nodes = net.getNodes()
        sumo_edges = net.getEdges()
        
        if len(sumo_nodes) == 0:
            raise ValidationError("SUMO loaded network has no nodes")
        if len(sumo_edges) == 0:
            raise ValidationError("SUMO loaded network has no edges")
        
        # Quick connectivity check on a sample of edges
        if sumo_edges:
            sample_edge = sumo_edges[0]
            if not sample_edge.getFromNode() or not sample_edge.getToNode():
                raise ValidationError("Network has edges with missing from/to nodes")
        
    except ImportError:
        # sumolib not available, skip this validation
        pass
    except Exception as exc:
        raise ValidationError(f"Network not loadable by SUMO: {exc}") from exc
    
    # 4 ── validate traffic light logic is reasonable ------------------------
    tl_logics = root.findall("tlLogic")
    tl_junctions = [j for j in junctions if j.get("type") == "traffic_light"]
    
    if tl_junctions and not tl_logics:
        raise ValidationError("Traffic light junctions found but no traffic light logic")
    
    # Check traffic light phases are valid
    for tl_logic in tl_logics:
        tl_id = tl_logic.get("id")
        phases = tl_logic.findall("phase")
        
        if not phases:
            raise ValidationError(f"Traffic light {tl_id} has no phases after rebuild")
        
        # Verify phases have valid states
        for phase in phases:
            state = phase.get("state", "")
            if not state:
                raise ValidationError(f"Traffic light {tl_id} has empty phase state")
    
    # 5 ── validate network coordinates are reasonable -----------------------
    try:
        x_coords = []
        y_coords = []
        
        for junction in visible_junctions:
            x = float(junction.get("x", 0))
            y = float(junction.get("y", 0))
            x_coords.append(x)
            y_coords.append(y)
        
        if x_coords and y_coords:
            x_range = max(x_coords) - min(x_coords)
            y_range = max(y_coords) - min(y_coords)
            
            # Network should have reasonable spatial extent
            if x_range < 50 or y_range < 50:
                raise ValidationError(f"Network spatial range too small: {x_range}×{y_range} meters")
                
    except ValueError as exc:
        raise ValidationError(f"Invalid coordinates in network: {exc}") from exc

    return


def verify_set_lane_counts(
    net_file_out: str | Path,
    *,
    min_lanes: int = 1,
    max_lanes: int = 3,
) -> None:
    """Validate lane counts and *practical* connectivity after mutation."""

    path = Path(net_file_out)
    if not path.exists():
        raise ValidationError(
            f"Lane‑count check: network file missing: {path}")

    try:
        net = sumolib.net.readNet(str(path))
    except Exception as exc:
        raise ValidationError(
            f"Failed to parse network file {path}: {exc}") from exc

    counts: list[int] = []
    unreachable: list[str] = []

    for edge in net.getEdges():
        func = edge.getFunction() if hasattr(
            edge, "getFunction") else edge.func  # type: ignore
        if func == "internal":
            continue
        lanes = edge.getLanes()
        counts.append(len(lanes))
        for lane in lanes:
            if not lane.getIncoming():
                unreachable.append(lane.getID())

    if not counts:
        raise ValidationError(
            "Lane‑count check: no driveable edges found in network")

    # Bound check ----------------------------------------------------------------
    bad = [c for c in counts if c < min_lanes or c > max_lanes]
    if bad:
        raise ValidationError(
            f"{len(bad)} edges have lane count outside [{min_lanes}, {max_lanes}]"
        )

    # Distribution check ---------------------------------------------------------
    if all(c == counts[0] for c in counts):
        raise ValidationError(
            "All edges share the same lane number; randomisation may have failed")
    if min_lanes not in counts:
        raise ValidationError(
            f"No edge ended up with the minimum lane count ({min_lanes})")
    if max_lanes not in counts:
        raise ValidationError(
            f"No edge ended up with the maximum lane count ({max_lanes})")

    # Connectivity check ---------------------------------------------------------
    if unreachable:
        # geometry helpers
        xmin, ymin, xmax, ymax = net.getBoundary()
        tol = 1e-3

        def on_border(node) -> bool:
            x, y = node.getCoord()
            return abs(x - xmin) < tol or abs(x - xmax) < tol or abs(y - ymin) < tol or abs(y - ymax) < tol

        interior_violations: list[str] = []
        for lane_id in unreachable:
            lane_obj = net.getLane(lane_id)
            edge = lane_obj.getEdge()

            # perimeter tolerance
            if on_border(edge.getFromNode()) and on_border(edge.getToNode()):
                continue

            # upstream‑lane‑count tolerance
            from_node = edge.getFromNode()
            max_in_lanes = max((len(e.getLanes())
                               for e in from_node.getIncoming()), default=0)
            try:
                lane_idx = int(lane_id.rsplit("_", 1)[-1])
            except ValueError:
                lane_idx = -1  # cannot parse, treat as interior

            if lane_idx >= max_in_lanes:
                continue  # tolerated: no upstream lane with this index exists

            interior_violations.append(lane_id)

        if interior_violations:
            sample = ", ".join(interior_violations[:5])
            more = "" if len(
                interior_violations) <= 5 else f" … and {len(interior_violations)-5} more"
            raise ValidationError(
                f"{len(interior_violations)} interior lanes have no incoming connection: {sample}{more}"
            )

    # all good
    return

# ---------------------------------------------------------------------------
#  Edge attractiveness verification (inline after assign_edge_attractiveness)
# ---------------------------------------------------------------------------

    """Validate *assign_edge_attractiveness* output.

Checks performed
----------------
1. **Presence**   Every non‑internal `<edge>` carries *both* XML attributes
   `depart_attractiveness` and `arrive_attractiveness`.
2. **Type & Range**   Values are non‑negative integers (netconvert often wraps a
   single‑lane value as `[3]`; brackets are stripped first).
3. **Distribution sanity**   The sample mean of each attribute must sit within
   ±50 % (default *tolerance*) of the corresponding Poisson λ used when the
   helper was called (`lambda_depart`, `lambda_arrive`).  This weeds out cases
   where the attribute was written but the random draw silently failed.
4. **Variability**   Rejects the degenerate case where every edge got the same
   value, indicating the random generator wasn’t invoked.
"""


def _mean(vals: list[int]) -> float:
    return sum(vals) / len(vals) if vals else float("nan")


def _to_float(val):
    """Coerce CLI values that sometimes arrive as tuple / str → float."""
    if isinstance(val, (list, tuple)):
        val = val[0]
    return float(val)


def verify_assign_edge_attractiveness(
    seed: int,
    net_file: str | Path,
    *,
    lambda_depart: float | str | tuple,
    lambda_arrive: float | str | tuple,
    tolerance: float = 0.5,  # ±50 % of λ is acceptable
) -> None:
    """Validate that attractiveness attributes exist and are plausible."""

    lambda_depart_f = _to_float(lambda_depart)
    lambda_arrive_f = _to_float(lambda_arrive)

    path = Path(net_file)
    if not path.exists():
        raise ValidationError(
            f"Attractiveness check: network file not found: {path}")

    tree = ET.parse(path)
    root = tree.getroot()

    dep_vals: list[int] = []
    arr_vals: list[int] = []

    for edge in root.findall("edge"):
        if edge.get("function") == "internal":
            continue

        dep = edge.get("depart_attractiveness")
        arr = edge.get("arrive_attractiveness")
        if dep is None or arr is None:
            raise ValidationError(
                f"Edge {edge.get('id')} missing attractiveness attributes")

        dep = dep.strip("[]")
        arr = arr.strip("[]")
        try:
            dep_i = int(dep)
            arr_i = int(arr)
        except ValueError:
            raise ValidationError(
                f"Edge {edge.get('id')} has non‑integer attractiveness value")
        if dep_i < 0 or arr_i < 0:
            raise ValidationError(
                f"Edge {edge.get('id')} has negative attractiveness value")

        dep_vals.append(dep_i)
        arr_vals.append(arr_i)

    # sample‑mean sanity ------------------------------------------------------
    dep_mean = _mean(dep_vals)
    arr_mean = _mean(arr_vals)

    if not (lambda_depart_f * (1 - tolerance) <= dep_mean <= lambda_depart_f * (1 + tolerance)):
        raise ValidationError(
            f"Depart attractiveness mean {dep_mean:.2f} outside ±{tolerance*100:.0f}% of λ={lambda_depart_f}")
    if not (lambda_arrive_f * (1 - tolerance) <= arr_mean <= lambda_arrive_f * (1 + tolerance)):
        raise ValidationError(
            f"Arrive attractiveness mean {arr_mean:.2f} outside ±{tolerance*100:.0f}% of λ={lambda_arrive_f}")

    # variability check -------------------------------------------------------
    if len(set(dep_vals)) <= 1 and len(set(arr_vals)) <= 1:
        raise ValidationError(
            "Attractiveness values appear constant; distribution sampling may have failed")

    return
